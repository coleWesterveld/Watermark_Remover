{"cells":[{"cell_type":"code","source":["# (c) Westerveld 2023\n","# final project - watermark remover\n","# Display of watermark remover autoencoder, takes image file and displays before and after"],"metadata":{"id":"undZm3Zwl8sG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"id":"2VKm0IHvHKa7","executionInfo":{"status":"ok","timestamp":1698279349727,"user_tz":240,"elapsed":589,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"}}},"outputs":[],"source":["# downloads zipped dataset and extracts, takes about 4 mins\n","#commented out because this is not needed unless testing the dataste specifically\n","\n","# !gdown 17y1gkUhIV6rZJg1gMG-gzVMnH27fm4Ij\n","\n","# !pip install pyunpack\n","# !pip install patool\n","# from pyunpack import Archive\n","# Archive(\"CLWD.rar\").extractall(\"\")"]},{"cell_type":"code","source":["# install what is the best model so far from google drive\n","\n","!gdown 1FOk6nV1x2cGB8iCnnMHWEg-gcVb5F0eQ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H57tmhWuFXG","executionInfo":{"status":"ok","timestamp":1698278878263,"user_tz":240,"elapsed":4693,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"}},"outputId":"08bdc090-29b1-45c4-a06b-377031dfab9b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1FOk6nV1x2cGB8iCnnMHWEg-gcVb5F0eQ\n","To: /content/save_epoch-5.pth\n","100% 5.69M/5.69M [00:00<00:00, 21.0MB/s]\n"]}]},{"cell_type":"code","source":["\n","# import libraries\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","from torchvision.io import read_image\n","from PIL import Image\n","import torchvision.transforms as T\n","import random"],"metadata":{"id":"Tjx5Y9Y4m5t8","executionInfo":{"status":"ok","timestamp":1698279352564,"user_tz":240,"elapsed":539,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"wONyQbRisyiR","executionInfo":{"status":"ok","timestamp":1698279354549,"user_tz":240,"elapsed":543,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"}}},"outputs":[],"source":["# custom dataset - returns watermarked image as image, and watermark free as label.\n","\n","class Watermark_Dataset(Dataset):\n","\n","  def __getitem__(self, idx):\n","      # get watermarked and corresponding watermark free image\n","      img_path = r\"CLWD/train/Watermarked_image/\" + str(idx + 1) + \".jpg\"\n","      watermarked = Image.open(img_path).convert('RGB')\n","      img_path = r\"CLWD/train/Watermark_free_image/\" + str(idx + 1) + \".jpg\"\n","      watermark_free = Image.open(img_path).convert('RGB')\n","\n","      # convert to tensor\n","      transform_one = T.ToTensor()\n","\n","      img = transform_one(watermarked)\n","      label = transform_one(watermark_free)\n","\n","      # return img and label\n","      return img.float(), label.float()\n","\n","  def __len__(self):\n","    #hardcoded length - number of watermarked/watermark free image pairs in datset\n","    return 60_000"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1059,"status":"ok","timestamp":1698279357052,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"},"user_tz":240},"id":"mcuGnWzluLmx","outputId":"553985d6-db77-4ffd-c9d9-b8e4bcac6915"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":31},{"output_type":"stream","name":"stdout","text":["epoch: 5\n","Loss: tensor(0.0086, device='cuda:0', requires_grad=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["Auto_Encoder(\n","  (encoder): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.1)\n","    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (3): LeakyReLU(negative_slope=0.1)\n","    (4): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n","  )\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n","  (decoder): Sequential(\n","    (0): ConvTranspose2d(64, 32, kernel_size=(7, 7), stride=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.1)\n","    (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (3): LeakyReLU(negative_slope=0.1)\n","    (4): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (5): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":31},{"output_type":"stream","name":"stdout","text":["3708\n"]}],"source":["# Model class - convolutional autoencoder\n","# scales down image with encoding which is then decoded with decoder.\n","# takes in 256x256 JPG images and returns 256x256 JPG images (has 3 channels for RGB)\n","\n","class Auto_Encoder(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # encoder - compresses the image\n","    self.encoder = nn.Sequential(\n","        nn.Conv2d(3, 16, 3, stride = 2, padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.Conv2d(16, 32, 3, stride = 2, padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.Conv2d(32, 64, 7),\n","\n","    )\n","\n","    # max pooling - takes max of the pixels in an area to compress\n","    self.pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n","    self.unpool = nn.MaxUnpool2d(2, stride=2)\n","\n","    # decoder - decompresses\n","    self.decoder = nn.Sequential(\n","        nn.ConvTranspose2d(64, 32, 7),\n","        nn.LeakyReLU(0.1),\n","        nn.ConvTranspose2d(32, 16, 3, stride = 2, padding = 1, output_padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.ConvTranspose2d(16, 3, 3, stride = 2, padding = 1, output_padding = 1),\n","        nn.Sigmoid()\n","\n","    )\n","  # output\n","  def forward(self, x):\n","\n","    encoded = self.encoder(x)\n","\n","    # pooling and unpooling\n","    output, indices = self.pool(encoded)\n","    unpooled = self.unpool(output, indices)\n","\n","    decoded = self.decoder(unpooled)\n","    return decoded\n","\n","#initialize model\n","model = Auto_Encoder()\n","\n","# load model from file\n","checkpoint = torch.load('save_epoch-5.pth')\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# print epoch and loss\n","epoch = checkpoint['epoch']\n","print(\"epoch:\", str(epoch))\n","loss = checkpoint['loss']\n","print(\"Loss:\", str(loss))\n","\n","# prepare to evaluate and not trianing - allow to take single image instead of batch, among other things\n","model.eval()\n","\n","\n","# just for demonstration it picks random image from dataset, but any image can be used by changing image path\n","idx = random.randint(1, 5_000)\n","path = r\"CLWD/test/Watermarked_image/\"+ str(idx) +\".jpg\"\n","im = Image.open(path)\n","im = im.resize((256, 256))\n","print(idx)\n","\n","# show initial\n","im.show()\n","\n","\n","\n","# convter to float tensor to pass through the model\n","transform = T.Compose([T.ToTensor()])\n","img_tensor = transform(im)\n","img_tensor = img_tensor.float()\n","\n","# run input through the model\n","output = model(img_tensor)\n","\n","path = r\"CLWD/test/Watermark_free_image/\"+ str(idx) +\".jpg\"\n","im = Image.open(path)\n","im = im.resize((256, 256))\n","\n","im.show()\n","\n","# dipslay image using Pillow\n","transform = T.ToPILImage()\n","img = transform(output)\n","img.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrRytvtknnt8"},"outputs":[],"source":["# Testing dataset - display watermarked and watermark free image\n","# mostly for bugfixing\n","Train_Data = Watermark_Dataset()\n","train_dataloader = DataLoader(Train_Data, batch_size=4, shuffle=True)\n","\n","# iterate features and labels\n","train_features, train_labels = next(iter(train_dataloader))\n","print(f\"Feature batch shape: {train_features.size()}\")\n","print(f\"Labels batch shape: {train_labels.size()}\")\n","\n","# get first image of the batch\n","img = train_features[0]\n","label = train_labels[0]\n","\n","# convert to image and display both\n","pic1 = transform(img)\n","pic1.show()\n","pic2 = transform(label)\n","pic2.show()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1lkUQpPkO5GIUuXmGGRQ6ISw6EiuDL1ji","timestamp":1686888651577},{"file_id":"1Um1VL3_KaSWGqHZeBVE4Eogl2XwdN5nA","timestamp":1686800699244}],"gpuType":"T4","authorship_tag":"ABX9TyNxudcuJpK/ej3NWxRLBp3z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}