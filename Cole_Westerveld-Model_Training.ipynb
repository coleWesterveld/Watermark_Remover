{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"myKQ0k5vljft"},"outputs":[],"source":["# (c) Westerveld 2023\n","# Watermark remover training and development using pytorch library with python\n","# A convolutional variational autoencoder that takes in an image with a watermark and (ideally) outputs the same image but without a watermark\n","# The architecture compresses the image then upsamples it, removing the watermark in the process and outputting an image.\n","# uses CLWD dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VKm0IHvHKa7","outputId":"5c46ea27-232e-45b2-f8b5-681a6d2138f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=17y1gkUhIV6rZJg1gMG-gzVMnH27fm4Ij\n","To: /content/CLWD.rar\n","100% 3.35G/3.35G [00:52<00:00, 63.3MB/s]\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyunpack\n","  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n","Collecting easyprocess (from pyunpack)\n","  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n","Collecting entrypoint2 (from pyunpack)\n","  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n","Installing collected packages: entrypoint2, easyprocess, pyunpack\n","Successfully installed easyprocess-1.1 entrypoint2-1.1 pyunpack-0.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting patool\n","  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: patool\n","Successfully installed patool-1.12\n"]}],"source":["# downloads zipped dataset and extracts, takes about 4 mins\n","# commented out because this is not needed unless testing the dataste specifically\n","\n","# !gdown 17y1gkUhIV6rZJg1gMG-gzVMnH27fm4Ij\n","\n","# !pip install pyunpack\n","# !pip install patool\n","# from pyunpack import Archive\n","# Archive(\"CLWD.rar\").extractall(\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5895,"status":"ok","timestamp":1696735719790,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"},"user_tz":420},"id":"OpICVzD8XzXG","outputId":"1fbbc5a0-a005-4624-ce82-577e647e7578"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# include libraries\n","#import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.io import read_image\n","from PIL import Image\n","import torchvision.transforms as T\n","\n","# check if gpu available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_hHozUR8fTx"},"outputs":[],"source":["# custom dataset - returns watermarked image as image, and watermark free as label.\n","\n","class Watermark_Dataset(Dataset):\n","\n","  def __getitem__(self, idx):\n","      # get watermarked and corresponding watermark free image\n","      img_path = r\"CLWD/train/Watermarked_image/\" + str(idx + 1) + \".jpg\"\n","      watermarked = Image.open(img_path).convert('RGB')\n","      img_path = r\"CLWD/train/Watermark_free_image/\" + str(idx + 1) + \".jpg\"\n","      watermark_free = Image.open(img_path).convert('RGB')\n","\n","      # convert to tensor\n","      transform_one = T.ToTensor()\n","\n","      img = transform_one(watermarked)\n","      label = transform_one(watermark_free)\n","\n","      # return img and label\n","      return img.float(), label.float()\n","\n","  def __len__(self):\n","    #hardcoded length - number of watermarked/watermark free image pairs in datset\n","    return 60_000\n","\n","# initialize dataset\n","Train_dataset = Watermark_Dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmE6EIhHhOrw"},"outputs":[],"source":["# Model class - convolutional autoencoder\n","# scales down image with encoding which is then decoded with decoder.\n","# takes in 256x256 JPG images and returns 256x256 JPG images (has 3 channels for RGB)\n","# at its lowest image is compressed to 29x29 image\n","\n","class Auto_Encoder(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # encoder - compresses the image\n","    self.encoder = nn.Sequential(\n","        nn.Conv2d(3, 16, 3, stride = 2, padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.Conv2d(16, 32, 3, stride = 2, padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.Conv2d(32, 64, 7),\n","    )\n","\n","    # max pooling - takes max of the pixels in an area to compress\n","    self.pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n","    self.unpool = nn.MaxUnpool2d(2, stride=2)\n","\n","    # decoder - decompresses\n","    self.decoder = nn.Sequential(\n","        nn.ConvTranspose2d(64, 32, 7),\n","        nn.LeakyReLU(0.1),\n","        nn.ConvTranspose2d(32, 16, 3, stride = 2, padding = 1, output_padding = 1),\n","        nn.LeakyReLU(0.1),\n","        nn.ConvTranspose2d(16, 3, 3, stride = 2, padding = 1, output_padding = 1),\n","        nn.Sigmoid()\n","    )\n","  # output\n","  def forward(self, x):\n","\n","    encoded = self.encoder(x)\n","\n","    # pooling and unpooling\n","    output, indices = self.pool(encoded)\n","    unpooled = self.unpool(output, indices)\n","\n","    decoded = self.decoder(unpooled)\n","    return decoded\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysmRxfFEvdjF"},"outputs":[],"source":["# initializing the model, optimizer and loss type.\n","# move model and criterion to GPU if available\n","model = Auto_Encoder()\n","criterion = nn.MSELoss()\n","model.to(device)\n","criterion.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2, weight_decay = 1e-4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fGjVlEte5_uB","executionInfo":{"status":"error","timestamp":1687495599888,"user_tz":420,"elapsed":15743,"user":{"displayName":"FlyPengiun 44","userId":"12676730952236288290"}},"outputId":"3c003487-ddf1-4962-cba6-3cfb4ab4ee29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jun 22 21:46:24 2023       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 531.18                 Driver Version: 531.18       CUDA Version: 12.1     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA GeForce GTX 1660 S...  WDDM | 00000000:2B:00.0  On |                  N/A |\n","| 43%   41C    P2               43W / 125W|   1411MiB /  6144MiB |      6%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|    0   N/A  N/A       928    C+G   ...oration\\NvContainer\\nvcontainer.exe    N/A      |\n","|    0   N/A  N/A      3972    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A      5088    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A      6280    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n","|    0   N/A  N/A      7616      C   ...0_x64__qbz5n2kfra8p0\\python3.10.exe    N/A      |\n","|    0   N/A  N/A      9796    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n","|    0   N/A  N/A     10876    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n","|    0   N/A  N/A     12532    C+G   ...304.0.0_x64__8wekyb3d8bbwe\\Time.exe    N/A      |\n","|    0   N/A  N/A     12620    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n","|    0   N/A  N/A     12768    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A     13088    C+G   C:\\Windows\\explorer.exe                   N/A      |\n","|    0   N/A  N/A     13464    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     14108    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     16192    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n","|    0   N/A  N/A     17040    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n","+---------------------------------------------------------------------------------------+\n","cuda:0\n","training at epoch  0   1.0 % done\n","training at epoch  0   2.0 % done\n","training at epoch  0   3.0 % done\n","training at epoch  0   4.0 % done\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# print progress\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m37.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mWatermark_Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# get watermarked and corresponding watermark free image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCole\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop/CLWD/CLWD/train/Watermarked_image/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     watermarked \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCole\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop/CLWD/CLWD/train/Watermark_free_image/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     watermark_free \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\Image.py:3140\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3137\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m   3138\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3140\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3142\u001b[0m preinit()\n\u001b[0;32m   3144\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# losses over the training epochs\n","losses = []\n","\n","# initialize dataloader\n","train_dataloader = DataLoader(Train_dataset, batch_size=4, shuffle=True)\n","# * if GPU is good enough num_workers argument can be added and set to ~10, depending on resources\n","\n","# see GPU stats just before training\n","!nvidia-smi\n","print(device)\n","\n","\n","# Training loop\n","transform = T.ToPILImage()\n","# if name == main makes windows system run GPU when sometimes it otherwise will not see the GPU, i dont really know why\n","# but thats what the forums said and it works\n","if __name__ == '__main__':\n","  epochs = 12\n","  for e in range(epochs):\n","      counter = 0\n","      running_loss = 0\n","      for images, labels in train_dataloader:\n","          # print progress\n","          counter += 1\n","          if counter % (37.5*4) == 0:\n","            print(\"training at epoch \", e, \" \", (counter / (3750 * 4)) * 100, \"% done\")\n","\n","          # data to GPU\n","          images = images.to(device)\n","          labels = labels.to(device)\n","\n","          # get output from autoencoder\n","          output = model(images)\n","\n","          # Data to GPU\n","          output.to(device)\n","\n","          # backpropagation and caculate loss\n","          optimizer.zero_grad()\n","          loss = criterion(output, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # keep track of loss\n","          running_loss += loss.item()\n","\n","      losses.append((running_loss)/15000)\n","\n","      # after each epoch, save model state to file to be tested later on\n","      torch.save({\n","              'epoch': e,\n","              'model_state_dict': model.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict(),\n","              'loss': loss,\n","              }, f\"seven-ice_more_epoch-{e}.pth\")\n","\n","# print losses over the epochs\n","print(losses)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1liQNZlLcYOeSqgkJgKSPMAr25mf4bnwA","authorship_tag":"ABX9TyNs0R0AUFVYhqtrZvkGWu99"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}